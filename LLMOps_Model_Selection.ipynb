{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AliNoorian/LLMOps_Series_Model_Selection/blob/main/LLMOps_Model_Selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18ae5f31",
      "metadata": {
        "id": "18ae5f31"
      },
      "source": [
        "\n",
        "# LLMOps Series — Model Selection (Colab/Jupyter Notebook)\n",
        "\n",
        "> **Use this notebook to choose, test, and cost out LLMs for your use case.**  \n",
        "> It includes setup cells, side‑by‑side comparisons (proprietary vs open‑source), latency/throughput tests, context‑window experiments, quantization notes, and lightweight benchmarking utilities.\n",
        "\n",
        "**Contents**\n",
        "1. [Environment Check & Setup](#env)\n",
        "2. [Your Use Case Checklist](#checklist)\n",
        "3. [Proprietary vs Open-Source: Decision Guide](#decision)\n",
        "4. [Open-Source: Try a Small Model (Transformers)](#transformers)\n",
        "5. [Open-Source: Try a GGUF Model (llama.cpp / llama-cpp-python)](#gguf)\n",
        "6. [Latency & Throughput Testing](#perf)\n",
        "7. [Context Window Experiments](#ctx)\n",
        "8. [Prompt Engineering vs Fine‑Tuning (Overview + Demo)](#tuning)\n",
        "9. [Cost Estimation — API & Self-Hosting Calculators](#cost)\n",
        "10. [Minimal RAG Harness (Optional)](#rag)\n",
        "11. [Production Inference (vLLM/TGI) — Optional Installs](#prod)\n",
        "12. [Quick Benchmarking Utilities](#bench)\n",
        "13. [References & Next Steps](#refs)\n",
        "\n",
        "---\n",
        "\n",
        "**Two Main Model Types**  \n",
        "**Proprietary** (e.g., GPT-5, Claude, Gemini) → _Plug-and-play_, top-tier performance, pay‑per‑use, limited data control.  \n",
        "**Open-Source** (e.g., LLaMA, Mistral, Falcon, Zephyr) → _Full control_, lower long‑term cost, infra/DevOps required.\n",
        "\n",
        "> **General rule:** Start fast with proprietary APIs, then migrate to open‑source for cost/privacy control.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea9846e2",
      "metadata": {
        "id": "ea9846e2"
      },
      "source": [
        "\n",
        "---\n",
        "<a id=\"env\"></a>\n",
        "\n",
        "## 1) Environment Check & Setup\n",
        "\n",
        "This section verifies Python version, GPU availability, and installs commonly used libraries.  \n",
        "Run each cell once per runtime.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4bfa9cd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4bfa9cd",
        "outputId": "8d904cb2-808e-4a6c-f8da-cb6df9a8afc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.12.11\n",
            "Platform: Linux-6.6.97+-x86_64-with-glibc2.35\n",
            "CUDA_VISIBLE_DEVICES: None\n",
            "Wed Sep 24 08:35:07 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import sys, platform, os, subprocess, json, textwrap, math, time, random\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"Python:\", sys.version.split()[0])\n",
        "print(\"Platform:\", platform.platform())\n",
        "print(\"CUDA_VISIBLE_DEVICES:\", os.environ.get(\"CUDA_VISIBLE_DEVICES\"))\n",
        "!nvidia-smi || echo \"No NVIDIA GPU detected.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31489f29",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31489f29",
        "outputId": "83f3e204-f988-4204-8c7f-2d4c82e1f1f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.6/503.6 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
            "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "\n",
        "# Core libraries used across the notebook\n",
        "!pip -q install transformers accelerate sentencepiece bitsandbytes --upgrade\n",
        "!pip -q install llama-cpp-python --upgrade\n",
        "# Optional helpers\n",
        "!pip -q install einops datasets evaluate tiktoken --upgrade\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b88a9844",
      "metadata": {
        "id": "b88a9844"
      },
      "source": [
        "\n",
        "---\n",
        "<a id=\"checklist\"></a>\n",
        "\n",
        "## 2) Your Use Case Checklist\n",
        "\n",
        "Before choosing a model, clarify:\n",
        "\n",
        "- **Use case**: chatbot, summarizer, code assistant, RAG, agent, etc.\n",
        "- **Privacy**: healthcare/finance/government constraints?\n",
        "- **Budget**: API pay‑per‑use vs GPU hosting?\n",
        "- **Scale**: daily active users (DAU), peak RPS, latency targets?\n",
        "- **Fit**: prompt‑only vs fine‑tune; domain‑specific data?\n",
        "\n",
        "Run the next cell to record your choices. You can re-run and modify anytime.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02b13e51",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02b13e51",
        "outputId": "958d88be-66ed-4703-fe38-4cad3d45abdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UseCaseConfig(name='My Assistant', use_case='chatbot', privacy_level='standard', budget_mode='api', target_latency_ms=800, target_rps=2.0, need_finetune=False, context_window_tokens=8000, notes='add any constraints here')\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from dataclasses import dataclass, asdict\n",
        "\n",
        "@dataclass\n",
        "class UseCaseConfig:\n",
        "    name: str = \"My Assistant\"\n",
        "    use_case: str = \"chatbot\"\n",
        "    privacy_level: str = \"standard\"  # options: standard, high, extreme\n",
        "    budget_mode: str = \"api\"         # options: api, self-host, hybrid\n",
        "    target_latency_ms: int = 800\n",
        "    target_rps: float = 2.0\n",
        "    need_finetune: bool = False\n",
        "    context_window_tokens: int = 8000\n",
        "    notes: str = \"add any constraints here\"\n",
        "\n",
        "cfg = UseCaseConfig()\n",
        "print(cfg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24dcadab",
      "metadata": {
        "id": "24dcadab"
      },
      "source": [
        "\n",
        "---\n",
        "<a id=\"decision\"></a>\n",
        "\n",
        "## 3) Proprietary vs Open‑Source — Decision Guide\n",
        "\n",
        "| Factor | Proprietary (GPT/Claude/Gemini) | Open-Source (LLaMA/Mistral/Falcon/Zephyr) |\n",
        "|---|---|---|\n",
        "| **Speed to MVP** | ◎ Fast | ○ Medium |\n",
        "| **Peak Quality** | ◎ Very high | ○ High (varies by model/size) |\n",
        "| **Cost at Scale** | △ Increases with usage | ◎ Can be cheaper long‑term |\n",
        "| **Data Control** | △ Limited | ◎ Full |\n",
        "| **Customization** | ○ Prompting & fine‑tune (sometimes) | ◎ Full (fine‑tune/quantize) |\n",
        "| **Ops Overhead** | ◎ Low | △ Requires MLOps/DevOps |\n",
        "\n",
        "**Rule of thumb:** Prototype on proprietary APIs → baseline quality/perf → evaluate open‑source (quantized) for cost/privacy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ec34d07",
      "metadata": {
        "id": "9ec34d07"
      },
      "source": [
        "\n",
        "---\n",
        "<a id=\"transformers\"></a>\n",
        "\n",
        "## 4) Open‑Source: Try a Small Model (Transformers)\n",
        "\n",
        "Below we load a small model to keep downloads quick in Colab. You can swap to any compatible causal LM on Hugging Face.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b9ca279",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452,
          "referenced_widgets": [
            "1330baf2f34d4d058da821cbcdc7aaca",
            "6209ba7f33844fa8bf14e0c0f4f6ef83",
            "c452ae385576406ca2612e1b702de62b",
            "29277739f2014bd082e924c41dfee858",
            "026736c57e1548b6aca2c2ec00522c3c",
            "d732b276ad404cf887f6ef261585f494",
            "300910990f344a32ac1e20854f1544ce",
            "b53aefc586a64bfbb46950e9f5d5363a",
            "3b2cb3b515e74cfa97c6c22f7549affb",
            "e18a884169cd4c889e89426236556c06",
            "9f09d3ebff244e3abb50fac35ab8cdef",
            "81a1af439fb84fb5a44d0cb67439d706",
            "3d20849d5b034ef58d9837e13d13dfc6",
            "beaa8c857e0b4ffea45f02dbe0d12fea",
            "c7c6fc395c7043c3b6671ccb08852979",
            "bd0dfbe0c18d4b21905b8c2c163a9d54",
            "740ab3e75caa46d295696df6c3dc3de7",
            "bf50d4c6331948b3b4f3599c4af167e9",
            "7442402e8d2b4b06a2b06135f67810fb",
            "94be58f611bf4aa3a98bdc7d256b87f1",
            "ceb4f9d082594cfd88075fb7e5c02a73",
            "6d5aaa1cff6647659a2d4e788a5ac98b",
            "0d1d684189ec49b6a62b4711e98a1ac8",
            "5dc0393445ec4f34a7370ad42d0b0524",
            "2fedc6806b25477394c138baa5d305fd",
            "789a547311cd4eec9056baf02cc5976f",
            "b272a5bf734d4cba8160cbd2601768f7",
            "cf08fdff699449558392cae4de86696f",
            "3ca625baccf14af6b1715d0dc7006ad3",
            "2545299c3f714fcfa3e04ee343424b06",
            "c9ee7be83be7403897c9c1b927a81418",
            "478bd0387cd6477ba3c878841b4230fa",
            "afaa38f7f4f8426d9c867433f43a764e",
            "4a5754bee5fe40f28ea6e890a09be929",
            "d0da55b2c95040b5ba4c6b8ae7388d4d",
            "77138d8c59e44093923042fc57f11a5c",
            "8f56836d42eb4e18be56a6e1ca7eb607",
            "299e652ea6324b32aa7004d2f0515d16",
            "16a784a4cccf47a6a7fa2412619ada5b",
            "896c43733b334990bb26031d6dbaaf49",
            "0935aa411ae846c9b2b51fe0424a13b5",
            "ddc7ad554ce845519c3fd0f617f7e07b",
            "6b051248a5d9420c82f075aff35b4495",
            "1b6fae02b7484c7eb783d52936e8c8b9",
            "d1a1f8bd85fb4918bfe38dccfaae41f1",
            "8501ce92f6ad4581b9081e4e6e7c8d26",
            "04b25e787c5047c3a4916dd8088b33ea",
            "9ab05ffcb6ba49258a4b164f7bd8a676",
            "30d23168407a497baadb233a7f306a9e",
            "473f26dd93db45928304c09bfa3f2bc0",
            "f174e76e5b9248dbb3b3e7540a94393d",
            "591c020562184e2890789e99114c8ec9",
            "4d9c5dce74d1436e908f6d8500354597",
            "8b52a596ea0440128c5e1a8d970f1ea2",
            "6f73e8681eb743b7b64914c29f5a7f5c",
            "75c3d67a93084be9844ba203dc48d52c",
            "31025a0cd960400f8385e655983fac17",
            "0b75562410d14eb78869e9ff2382eaea",
            "035f1787173f441fb413e08fe6209233",
            "21e6cc2eb7cd4338b5cb573198911497",
            "964dd94dccc64b5892d5eacc40d3a452",
            "777fab9116494c7281b2be9ea1798e15",
            "da249dbf238c4ee1baa8c0adfaac307f",
            "5b9d7b2f7e5e49bfa1a3939e9b392666",
            "25aca7014a5d42a1b10a135670ad12c0",
            "307c263bd89040369236d2510ca1a566",
            "5218a69321cf40068a76c302b24e6383",
            "d9f02d0568e74fc8afbd64e40fe841c4",
            "44432f62b7734fb985d0a40d4490aa96",
            "3e347c130aa44f5c8a8bfb45d9c02a60",
            "310be2c63044459f837cc03d34b2703f",
            "5415dafe377a4e3fa476235ef96b3d2b",
            "fef07525a9444e189adb7f0e9963a939",
            "f3124fe149dc4220adff89dbeeb8d9b2",
            "2621420502a54693a51013501f3eb1ec",
            "4f8a410785b540d097c69c7dadb90e2c",
            "c8daf70b7d0f441989e4273c511c1066"
          ]
        },
        "id": "3b9ca279",
        "outputId": "1aed9caa-6909-4ee3-933f-760b6abb260a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading: TinyLlama/TinyLlama-1.1B-Chat-v1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1330baf2f34d4d058da821cbcdc7aaca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "81a1af439fb84fb5a44d0cb67439d706"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d1d684189ec49b6a62b4711e98a1ac8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a5754bee5fe40f28ea6e890a09be929"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d1a1f8bd85fb4918bfe38dccfaae41f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75c3d67a93084be9844ba203dc48d52c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5218a69321cf40068a76c302b24e6383"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are a helpful assistant. Q: What's a good first step for LLM model selection?A: Start with a simple model and then add more layers to it. Q: How can I make sure my LLM model is not overfitting?A: Use regularization techniques like dropout, weight decay, and batch normalization. Q: How can I improve the performance of my LLM model on a specific task?A: Fine-tune the model on a specific task using a smaller dataset. Q: How can I evaluate the performance of my LLM model on a new task?A: Use a validation set and compare the performance to the performance on the original task. Q\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "import torch, os\n",
        "\n",
        "# Choose a lightweight model for demo\n",
        "model_id = os.environ.get(\"DEMO_MODEL_ID\", \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
        "\n",
        "print(\"Loading:\", model_id)\n",
        "tok = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=model, tokenizer=tok, device_map=\"auto\")\n",
        "res = pipe(\"You are a helpful assistant. Q: What's a good first step for LLM model selection?A:\", max_new_tokens=120, do_sample=False)\n",
        "print(res[0]['generated_text'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4764f050",
      "metadata": {
        "id": "4764f050"
      },
      "source": [
        "\n",
        "---\n",
        "<a id=\"gguf\"></a>\n",
        "\n",
        "## 5) Open‑Source: Try a GGUF Model (llama.cpp via `llama-cpp-python`)\n",
        "\n",
        "**GGUF** enables running quantized models on CPU/GPU with low memory. Below is a small demo using a tiny GGUF model.  \n",
        "Swap `gguf_url` to another model if desired (check model license/terms).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcab95f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcab95f7",
        "outputId": "fdc65196-9ede-4bc7-afc8-0cfbd6083bac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading tiny GGUF...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 23 key-value pairs and 201 tensors from /content/gguf_models/tinyllama-1.1b-chat-v1.0.Q4_0.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = tinyllama_tinyllama-1.1b-chat-v1.0\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 2048\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 2048\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 22\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 5632\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 64\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 4\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
            "llama_model_loader: - kv  11:                          general.file_type u32              = 2\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  16:                      tokenizer.ggml.merges arr[str,61249]   = [\"▁ t\", \"e r\", \"i n\", \"▁ a\", \"e n...\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  18:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  19:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  20:            tokenizer.ggml.padding_token_id u32              = 2\n",
            "llama_model_loader: - kv  21:                    tokenizer.chat_template str              = {% for message in messages %}\\n{% if m...\n",
            "llama_model_loader: - kv  22:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   45 tensors\n",
            "llama_model_loader: - type q4_0:  155 tensors\n",
            "llama_model_loader: - type q6_K:    1 tensors\n",
            "print_info: file format = GGUF V3 (latest)\n",
            "print_info: file type   = Q4_0\n",
            "print_info: file size   = 606.53 MiB (4.63 BPW) \n",
            "init_tokenizer: initializing tokenizer for type 1\n",
            "load: control token:      2 '</s>' is not marked as EOG\n",
            "load: control token:      1 '<s>' is not marked as EOG\n",
            "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
            "load: printing all EOG tokens:\n",
            "load:   - 2 ('</s>')\n",
            "load: special tokens cache size = 3\n",
            "load: token to piece cache size = 0.1684 MB\n",
            "print_info: arch             = llama\n",
            "print_info: vocab_only       = 0\n",
            "print_info: n_ctx_train      = 2048\n",
            "print_info: n_embd           = 2048\n",
            "print_info: n_layer          = 22\n",
            "print_info: n_head           = 32\n",
            "print_info: n_head_kv        = 4\n",
            "print_info: n_rot            = 64\n",
            "print_info: n_swa            = 0\n",
            "print_info: is_swa_any       = 0\n",
            "print_info: n_embd_head_k    = 64\n",
            "print_info: n_embd_head_v    = 64\n",
            "print_info: n_gqa            = 8\n",
            "print_info: n_embd_k_gqa     = 256\n",
            "print_info: n_embd_v_gqa     = 256\n",
            "print_info: f_norm_eps       = 0.0e+00\n",
            "print_info: f_norm_rms_eps   = 1.0e-05\n",
            "print_info: f_clamp_kqv      = 0.0e+00\n",
            "print_info: f_max_alibi_bias = 0.0e+00\n",
            "print_info: f_logit_scale    = 0.0e+00\n",
            "print_info: f_attn_scale     = 0.0e+00\n",
            "print_info: n_ff             = 5632\n",
            "print_info: n_expert         = 0\n",
            "print_info: n_expert_used    = 0\n",
            "print_info: causal attn      = 1\n",
            "print_info: pooling type     = 0\n",
            "print_info: rope type        = 0\n",
            "print_info: rope scaling     = linear\n",
            "print_info: freq_base_train  = 10000.0\n",
            "print_info: freq_scale_train = 1\n",
            "print_info: n_ctx_orig_yarn  = 2048\n",
            "print_info: rope_finetuned   = unknown\n",
            "print_info: model type       = 1B\n",
            "print_info: model params     = 1.10 B\n",
            "print_info: general.name     = tinyllama_tinyllama-1.1b-chat-v1.0\n",
            "print_info: vocab type       = SPM\n",
            "print_info: n_vocab          = 32000\n",
            "print_info: n_merges         = 0\n",
            "print_info: BOS token        = 1 '<s>'\n",
            "print_info: EOS token        = 2 '</s>'\n",
            "print_info: UNK token        = 0 '<unk>'\n",
            "print_info: PAD token        = 2 '</s>'\n",
            "print_info: LF token         = 13 '<0x0A>'\n",
            "print_info: EOG token        = 2 '</s>'\n",
            "print_info: max token length = 48\n",
            "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
            "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   7 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   8 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   9 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  10 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  12 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  13 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  14 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  15 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  16 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  17 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  18 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  19 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  20 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  21 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  22 assigned to device CPU, is_swa = 0\n",
            "load_tensors: tensor 'token_embd.weight' (q4_0) (and 46 others) cannot be used with preferred buffer type CPU_REPACK, using CPU instead\n",
            "load_tensors:   CPU_REPACK model buffer size =   519.75 MiB\n",
            "load_tensors:   CPU_Mapped model buffer size =   606.53 MiB\n",
            "repack: repack tensor blk.0.attn_q.weight with q4_0_8x8\n",
            "repack: repack tensor blk.0.attn_k.weight with q4_0_8x8\n",
            "repack: repack tensor blk.0.attn_v.weight with q4_0_8x8\n",
            "repack: repack tensor blk.0.attn_output.weight with q4_0_8x8\n",
            "repack: repack tensor blk.0.ffn_gate.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.0.ffn_down.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.0.ffn_up.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.1.attn_q.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.1.attn_k.weight with q4_0_8x8\n",
            "repack: repack tensor blk.1.attn_v.weight with q4_0_8x8\n",
            "repack: repack tensor blk.1.attn_output.weight with q4_0_8x8\n",
            "repack: repack tensor blk.1.ffn_gate.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.1.ffn_down.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.1.ffn_up.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.2.attn_q.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.2.attn_k.weight with q4_0_8x8\n",
            "repack: repack tensor blk.2.attn_v.weight with q4_0_8x8\n",
            "repack: repack tensor blk.2.attn_output.weight with q4_0_8x8\n",
            "repack: repack tensor blk.2.ffn_gate.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.2.ffn_down.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.2.ffn_up.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.3.attn_q.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.3.attn_k.weight with q4_0_8x8\n",
            "repack: repack tensor blk.3.attn_v.weight with q4_0_8x8\n",
            "repack: repack tensor blk.3.attn_output.weight with q4_0_8x8\n",
            "repack: repack tensor blk.3.ffn_gate.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.3.ffn_down.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.3.ffn_up.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.4.attn_q.weight with q4_0_8x8\n",
            "repack: repack tensor blk.4.attn_k.weight with q4_0_8x8\n",
            "repack: repack tensor blk.4.attn_v.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.4.attn_output.weight with q4_0_8x8\n",
            "repack: repack tensor blk.4.ffn_gate.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.4.ffn_down.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.4.ffn_up.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.5.attn_q.weight with q4_0_8x8\n",
            "repack: repack tensor blk.5.attn_k.weight with q4_0_8x8\n",
            "repack: repack tensor blk.5.attn_v.weight with q4_0_8x8\n",
            "repack: repack tensor blk.5.attn_output.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.5.ffn_gate.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.5.ffn_down.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.5.ffn_up.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.6.attn_q.weight with q4_0_8x8\n",
            "repack: repack tensor blk.6.attn_k.weight with q4_0_8x8\n",
            "repack: repack tensor blk.6.attn_v.weight with q4_0_8x8\n",
            "repack: repack tensor blk.6.attn_output.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.6.ffn_gate.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.6.ffn_down.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.6.ffn_up.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.7.attn_q.weight with q4_0_8x8\n",
            "repack: repack tensor blk.7.attn_k.weight with q4_0_8x8\n",
            "repack: repack tensor blk.7.attn_v.weight with q4_0_8x8\n",
            "repack: repack tensor blk.7.attn_output.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.7.ffn_gate.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.7.ffn_down.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.7.ffn_up.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.8.attn_q.weight with q4_0_8x8\n",
            "repack: repack tensor blk.8.attn_k.weight with q4_0_8x8\n",
            "repack: repack tensor blk.8.attn_v.weight with q4_0_8x8\n",
            "repack: repack tensor blk.8.attn_output.weight with q4_0_8x8\n",
            "repack: repack tensor blk.8.ffn_gate.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.8.ffn_down.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.8.ffn_up.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.9.attn_q.weight with q4_0_8x8\n",
            "repack: repack tensor blk.9.attn_k.weight with q4_0_8x8\n",
            "repack: repack tensor blk.9.attn_v.weight with q4_0_8x8\n",
            "repack: repack tensor blk.9.attn_output.weight with q4_0_8x8\n",
            "repack: repack tensor blk.9.ffn_gate.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.9.ffn_down.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.9.ffn_up.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.10.attn_q.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.10.attn_k.weight with q4_0_8x8\n",
            "repack: repack tensor blk.10.attn_v.weight with q4_0_8x8\n",
            "repack: repack tensor blk.10.attn_output.weight with q4_0_8x8\n",
            "repack: repack tensor blk.10.ffn_gate.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.10.ffn_down.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.10.ffn_up.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.11.attn_q.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.11.attn_k.weight with q4_0_8x8\n",
            "repack: repack tensor blk.11.attn_v.weight with q4_0_8x8\n",
            "repack: repack tensor blk.11.attn_output.weight with q4_0_8x8\n",
            "repack: repack tensor blk.11.ffn_gate.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.11.ffn_down.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.11.ffn_up.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.12.attn_q.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.12.attn_k.weight with q4_0_8x8\n",
            "repack: repack tensor blk.12.attn_v.weight with q4_0_8x8\n",
            "repack: repack tensor blk.12.attn_output.weight with q4_0_8x8\n",
            "repack: repack tensor blk.12.ffn_gate.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.12.ffn_down.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.12.ffn_up.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.13.attn_q.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.13.attn_k.weight with q4_0_8x8\n",
            "repack: repack tensor blk.13.attn_v.weight with q4_0_8x8\n",
            "repack: repack tensor blk.13.attn_output.weight with q4_0_8x8\n",
            "repack: repack tensor blk.13.ffn_gate.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.13.ffn_down.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.13.ffn_up.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.14.attn_q.weight with q4_0_8x8\n",
            "repack: repack tensor blk.14.attn_k.weight with q4_0_8x8\n",
            "repack: repack tensor blk.14.attn_v.weight with q4_0_8x8\n",
            "repack: repack tensor blk.14.attn_output.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.14.ffn_gate.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.14.ffn_down.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.14.ffn_up.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.15.attn_q.weight with q4_0_8x8\n",
            "repack: repack tensor blk.15.attn_k.weight with q4_0_8x8\n",
            "repack: repack tensor blk.15.attn_v.weight with q4_0_8x8\n",
            "repack: repack tensor blk.15.attn_output.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.15.ffn_gate.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.15.ffn_down.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.15.ffn_up.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.16.attn_q.weight with q4_0_8x8\n",
            "repack: repack tensor blk.16.attn_k.weight with q4_0_8x8\n",
            "repack: repack tensor blk.16.attn_v.weight with q4_0_8x8\n",
            "repack: repack tensor blk.16.attn_output.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.16.ffn_gate.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.16.ffn_down.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.16.ffn_up.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.17.attn_q.weight with q4_0_8x8\n",
            "repack: repack tensor blk.17.attn_k.weight with q4_0_8x8\n",
            "repack: repack tensor blk.17.attn_v.weight with q4_0_8x8\n",
            "repack: repack tensor blk.17.attn_output.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.17.ffn_gate.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.17.ffn_down.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.17.ffn_up.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.18.attn_q.weight with q4_0_8x8\n",
            "repack: repack tensor blk.18.attn_k.weight with q4_0_8x8\n",
            "repack: repack tensor blk.18.attn_v.weight with q4_0_8x8\n",
            "repack: repack tensor blk.18.attn_output.weight with q4_0_8x8\n",
            "repack: repack tensor blk.18.ffn_gate.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.18.ffn_down.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.18.ffn_up.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.19.attn_q.weight with q4_0_8x8\n",
            "repack: repack tensor blk.19.attn_k.weight with q4_0_8x8\n",
            "repack: repack tensor blk.19.attn_v.weight with q4_0_8x8\n",
            "repack: repack tensor blk.19.attn_output.weight with q4_0_8x8\n",
            "repack: repack tensor blk.19.ffn_gate.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.19.ffn_down.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.19.ffn_up.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.20.attn_q.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.20.attn_k.weight with q4_0_8x8\n",
            "repack: repack tensor blk.20.attn_v.weight with q4_0_8x8\n",
            "repack: repack tensor blk.20.attn_output.weight with q4_0_8x8\n",
            "repack: repack tensor blk.20.ffn_gate.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.20.ffn_down.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.20.ffn_up.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.21.attn_q.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.21.attn_k.weight with q4_0_8x8\n",
            "repack: repack tensor blk.21.attn_v.weight with q4_0_8x8\n",
            "repack: repack tensor blk.21.attn_output.weight with q4_0_8x8\n",
            "repack: repack tensor blk.21.ffn_gate.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.21.ffn_down.weight with q4_0_8x8\n",
            ".repack: repack tensor blk.21.ffn_up.weight with q4_0_8x8\n",
            "....\n",
            "llama_context: constructing llama_context\n",
            "llama_context: n_seq_max     = 1\n",
            "llama_context: n_ctx         = 2048\n",
            "llama_context: n_ctx_per_seq = 2048\n",
            "llama_context: n_batch       = 512\n",
            "llama_context: n_ubatch      = 512\n",
            "llama_context: causal_attn   = 1\n",
            "llama_context: flash_attn    = 0\n",
            "llama_context: kv_unified    = false\n",
            "llama_context: freq_base     = 10000.0\n",
            "llama_context: freq_scale    = 1\n",
            "set_abort_callback: call\n",
            "llama_context:        CPU  output buffer size =     0.12 MiB\n",
            "create_memory: n_ctx = 2048 (padded)\n",
            "llama_kv_cache_unified: layer   0: dev = CPU\n",
            "llama_kv_cache_unified: layer   1: dev = CPU\n",
            "llama_kv_cache_unified: layer   2: dev = CPU\n",
            "llama_kv_cache_unified: layer   3: dev = CPU\n",
            "llama_kv_cache_unified: layer   4: dev = CPU\n",
            "llama_kv_cache_unified: layer   5: dev = CPU\n",
            "llama_kv_cache_unified: layer   6: dev = CPU\n",
            "llama_kv_cache_unified: layer   7: dev = CPU\n",
            "llama_kv_cache_unified: layer   8: dev = CPU\n",
            "llama_kv_cache_unified: layer   9: dev = CPU\n",
            "llama_kv_cache_unified: layer  10: dev = CPU\n",
            "llama_kv_cache_unified: layer  11: dev = CPU\n",
            "llama_kv_cache_unified: layer  12: dev = CPU\n",
            "llama_kv_cache_unified: layer  13: dev = CPU\n",
            "llama_kv_cache_unified: layer  14: dev = CPU\n",
            "llama_kv_cache_unified: layer  15: dev = CPU\n",
            "llama_kv_cache_unified: layer  16: dev = CPU\n",
            "llama_kv_cache_unified: layer  17: dev = CPU\n",
            "llama_kv_cache_unified: layer  18: dev = CPU\n",
            "llama_kv_cache_unified: layer  19: dev = CPU\n",
            "llama_kv_cache_unified: layer  20: dev = CPU\n",
            "llama_kv_cache_unified: layer  21: dev = CPU\n",
            "llama_kv_cache_unified:        CPU KV buffer size =    44.00 MiB\n",
            "llama_kv_cache_unified: size =   44.00 MiB (  2048 cells,  22 layers,  1/1 seqs), K (f16):   22.00 MiB, V (f16):   22.00 MiB\n",
            "llama_context: enumerating backends\n",
            "llama_context: backend_ptrs.size() = 1\n",
            "llama_context: max_nodes = 1608\n",
            "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
            "llama_context:        CPU compute buffer size =   149.01 MiB\n",
            "llama_context: graph nodes  = 776\n",
            "llama_context: graph splits = 1\n",
            "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | \n",
            "Model metadata: {'tokenizer.chat_template': \"{% for message in messages %}\\n{% if message['role'] == 'user' %}\\n{{ '<|user|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'system' %}\\n{{ '<|system|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'assistant' %}\\n{{ '<|assistant|>\\n'  + message['content'] + eos_token }}\\n{% endif %}\\n{% if loop.last and add_generation_prompt %}\\n{{ '<|assistant|>' }}\\n{% endif %}\\n{% endfor %}\", 'tokenizer.ggml.padding_token_id': '2', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '10000.000000', 'llama.context_length': '2048', 'general.name': 'tinyllama_tinyllama-1.1b-chat-v1.0', 'llama.embedding_length': '2048', 'llama.feed_forward_length': '5632', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '64', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '22', 'llama.attention.head_count_kv': '4', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '2'}\n",
            "Available chat formats from metadata: chat_template.default\n",
            "Using gguf chat template: {% for message in messages %}\n",
            "{% if message['role'] == 'user' %}\n",
            "{{ '<|user|>\n",
            "' + message['content'] + eos_token }}\n",
            "{% elif message['role'] == 'system' %}\n",
            "{{ '<|system|>\n",
            "' + message['content'] + eos_token }}\n",
            "{% elif message['role'] == 'assistant' %}\n",
            "{{ '<|assistant|>\n",
            "'  + message['content'] + eos_token }}\n",
            "{% endif %}\n",
            "{% if loop.last and add_generation_prompt %}\n",
            "{{ '<|assistant|>' }}\n",
            "{% endif %}\n",
            "{% endfor %}\n",
            "Using chat eos_token: </s>\n",
            "Using chat bos_token: <s>\n",
            "llama_perf_context_print:        load time =    2958.97 ms\n",
            "llama_perf_context_print: prompt eval time =    2958.73 ms /    19 tokens (  155.72 ms per token,     6.42 tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2959.51 ms /    20 tokens\n",
            "llama_perf_context_print:    graphs reused =          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os, urllib.request, pathlib, shutil\n",
        "from llama_cpp import Llama\n",
        "\n",
        "base_dir = pathlib.Path(\"/content\") if pathlib.Path(\"/content\").exists() else pathlib.Path(\".\")\n",
        "gguf_dir = base_dir / \"gguf_models\"\n",
        "gguf_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# A tiny GGUF for quick demo. Replace with another GGUF URL if you prefer.\n",
        "# Example sources: TheBloke/*-GGUF on Hugging Face (respect licenses).\n",
        "gguf_url = os.environ.get(\"DEMO_GGUF_URL\",\n",
        "    \"https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q4_0.gguf\" # tiny GGUF model\n",
        ")\n",
        "gguf_path = gguf_dir / \"tinyllama-1.1b-chat-v1.0.Q4_0.gguf\"\n",
        "\n",
        "if not gguf_path.exists():\n",
        "    print(\"Downloading tiny GGUF...\")\n",
        "    urllib.request.urlretrieve(gguf_url, gguf_path)\n",
        "else:\n",
        "    print(\"GGUF already present:\", gguf_path)\n",
        "\n",
        "llm = Llama(model_path=str(gguf_path), n_ctx=2048, n_threads=os.cpu_count())\n",
        "out = llm(\"Q: Give me one sentence about why GGUF can be useful.A:\", max_tokens=64, stop=[\"\"])\n",
        "print(out[\"choices\"][0][\"text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a84df1b1",
      "metadata": {
        "id": "a84df1b1"
      },
      "source": [
        "\n",
        "---\n",
        "<a id=\"perf\"></a>\n",
        "\n",
        "## 6) Latency & Throughput Testing\n",
        "\n",
        "**Latency:** time to first token / full response.  \n",
        "**Throughput:** requests per second (RPS) or tokens/sec under load.\n",
        "\n",
        "Below: simple utilities to measure both on the current pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3e3f4c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3e3f4c3",
        "outputId": "2769f479-fdd4-41e5-a9bf-cb8362b119aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latency (ms) per request: [4546.9, 1633.2, 114.3, 56.6, 62.9]\n",
            "Avg: 1282.8 ms | p95: 6586.5 ms\n",
            "Completed 4 requests in 6.63s → 0.60 RPS\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import time, statistics, asyncio\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "def time_single_inference(prompt, max_new_tokens=64):\n",
        "    t0 = time.perf_counter()\n",
        "    _ = pipe(prompt, max_new_tokens=max_new_tokens, do_sample=False)\n",
        "    t1 = time.perf_counter()\n",
        "    return (t1 - t0) * 1000  # ms\n",
        "\n",
        "# Warmup\n",
        "_ = pipe(\"Warmup.\", max_new_tokens=8, do_sample=False)\n",
        "\n",
        "prompts = [f\"Prompt {i}: Summarize LLMOps model selection in 1 sentence.\" for i in range(5)]\n",
        "latencies = [time_single_inference(p, 64) for p in prompts]\n",
        "print(\"Latency (ms) per request:\", [round(x,1) for x in latencies])\n",
        "print(\"Avg:\", round(statistics.mean(latencies),1), \"ms | p95:\", round(statistics.quantiles(latencies, n=20)[-1],1), \"ms\")\n",
        "\n",
        "# Simple concurrent throughput test\n",
        "def run_one(p):\n",
        "    return pipe(p, max_new_tokens=32, do_sample=False)\n",
        "\n",
        "async def concurrent_test(n=5):\n",
        "    loop = asyncio.get_event_loop()\n",
        "    with ThreadPoolExecutor(max_workers=n) as ex:\n",
        "        t0 = time.perf_counter()\n",
        "        futs = [loop.run_in_executor(ex, run_one, f\"Concurrent {i}: Say 'ok'.\") for i in range(n)]\n",
        "        res = await asyncio.gather(*futs)\n",
        "        t1 = time.perf_counter()\n",
        "    total_time = t1 - t0\n",
        "    print(f\"Completed {n} requests in {total_time:.2f}s → {n/total_time:.2f} RPS\")\n",
        "\n",
        "await concurrent_test(4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "000e9d5b",
      "metadata": {
        "id": "000e9d5b"
      },
      "source": [
        "\n",
        "---\n",
        "<a id=\"ctx\"></a>\n",
        "\n",
        "## 7) Context Window Experiments\n",
        "\n",
        "Test how performance changes as you increase input length. Use this to pick the right **context window** for your use case.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "359af1eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "359af1eb",
        "outputId": "d135b5a2-fc98-45b8-f502-5f874e7f4460"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input ~200 words → time 4.24s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4492 > 2048). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input ~1000 words → time 3.55s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (2048). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input ~3000 words → time 8.29s\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def synth_context(n_words=1000):\n",
        "    # Generate a synthetic passage ~n_words\n",
        "    words = [\"llmops\",\"scaling\",\"latency\",\"throughput\",\"quantization\",\"context\",\"window\",\"benchmark\",\"tokens\",\"inference\"]\n",
        "    return \" \".join(random.choice(words) for _ in range(n_words))\n",
        "\n",
        "for words in [200, 1000, 3000]:\n",
        "    ctx = synth_context(words)\n",
        "    t0 = time.perf_counter()\n",
        "    _ = pipe(f\"Read this and answer in 1 sentence: {ctx}\\nQuestion: What are two performance levers?\", max_new_tokens=64, do_sample=False)\n",
        "    t1 = time.perf_counter()\n",
        "    print(f\"Input ~{words} words → time {t1 - t0:.2f}s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abb42fc9",
      "metadata": {
        "id": "abb42fc9"
      },
      "source": [
        "\n",
        "---\n",
        "<a id=\"tuning\"></a>\n",
        "\n",
        "## 8) Prompt Engineering vs Fine‑Tuning\n",
        "\n",
        "- **Prompting**: Fast to iterate, zero training cost.\n",
        "- **Fine‑tuning**: Best for domain/format adherence & compliance. For small tasks, use **LoRA/QLoRA** to reduce cost.\n",
        "\n",
        "Below is a *minimal* LoRA fine‑tune sketch (pseudo‑small dataset) you can adapt. For real training, increase data/epochs and enable GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5ce1c80",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771,
          "referenced_widgets": [
            "ae5ed96214484b5c854287a75a504843",
            "471cd89d8a1643ec92c87f1fadc8dd6d",
            "4a341e627022403ea643012bafae7f1a",
            "025e930932ab4cfdbf7f22f43722f8f3",
            "8293473af8fe436c8617b34d9f0fc910",
            "a37b8f1b08d441668689ed4f2c7a5669",
            "38dba11c910f4ff9b16e5460708c1ef8",
            "ae411a8f8c594eeb91564eeee05d0ccc",
            "440bab68bf2b4aa4bd5ec72286af9628",
            "8220d587b722495cab9361b6d35e972e",
            "b2904008c1344ecd83ede657690b009b"
          ]
        },
        "id": "d5ce1c80",
        "outputId": "a4b89aed-e332-4e4b-8a98-c43db33f5241"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae5ed96214484b5c854287a75a504843"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnoorian-ali07\u001b[0m (\u001b[33mnoorian-ali07-ert\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250924_084742-9wz3kdok</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/noorian-ali07-ert/huggingface/runs/9wz3kdok' target=\"_blank\">curious-rain-1</a></strong> to <a href='https://wandb.ai/noorian-ali07-ert/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/noorian-ali07-ert/huggingface' target=\"_blank\">https://wandb.ai/noorian-ali07-ert/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/noorian-ali07-ert/huggingface/runs/9wz3kdok' target=\"_blank\">https://wandb.ai/noorian-ali07-ert/huggingface/runs/9wz3kdok</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 00:01, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.480300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4.800200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.284900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>4.610900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>3.137000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>4.476400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>4.424900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2.974100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>4.327100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.928600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Instruction: In one sentence, define LLMOps.\n",
            "### Response: LLMOps is a set of tools and techniques that enable the efficient and effective management of large-scale, distributed, and heterogeneous data centers. It includes tools for monitoring, automation, and optimization of data center infrastructure, as well as tools for managing and analyzing data center\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Minimal LoRA sketch using PEFT (optional)\n",
        "!pip -q install peft datasets --upgrade\n",
        "\n",
        "from datasets import Dataset\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "# Tiny toy dataset (replace with your domain data)\n",
        "train_texts = [\n",
        "    \"### Instruction: In one sentence, define LLMOps.\\n### Response: LLMOps is the practice of operating, monitoring, and optimizing large language model systems in production.\",\n",
        "    \"### Instruction: List two ways to reduce latency.\\n### Response: Use quantization and faster inference backends like vLLM or TGI.\"\n",
        "]\n",
        "dataset = Dataset.from_dict({\"text\": train_texts})\n",
        "\n",
        "tok2 = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", use_fast=True)\n",
        "base = AutoModelForCausalLM.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
        "dc = DataCollatorForLanguageModeling(tok2, mlm=False)\n",
        "\n",
        "lora_cfg = LoraConfig(r=8, lora_alpha=16, target_modules=[\"q_proj\",\"v_proj\"], lora_dropout=0.05, bias=\"none\", task_type=\"CAUSAL_LM\")\n",
        "peft_model = get_peft_model(base, lora_cfg)\n",
        "\n",
        "def tok_fn(batch):\n",
        "    return tok2(batch[\"text\"], truncation=True, max_length=512)\n",
        "\n",
        "tok_ds = dataset.map(tok_fn, batched=True)\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./lora-out\",\n",
        "    per_device_train_batch_size=1,\n",
        "    num_train_epochs=1,\n",
        "    learning_rate=2e-4,\n",
        "    logging_steps=1,\n",
        "    save_steps=5,\n",
        "    max_steps=10\n",
        ")\n",
        "trainer = Trainer(model=peft_model, args=args, data_collator=dc, train_dataset=tok_ds)\n",
        "trainer.train()\n",
        "\n",
        "# Inference with adapted model\n",
        "pipe_lora = pipeline(\"text-generation\", model=peft_model, tokenizer=tok2, device_map=\"auto\")\n",
        "print(pipe_lora(\"### Instruction: In one sentence, define LLMOps.\\n### Response:\", max_new_tokens=60, do_sample=False)[0]['generated_text'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61edc3a2",
      "metadata": {
        "id": "61edc3a2"
      },
      "source": [
        "\n",
        "---\n",
        "<a id=\"cost\"></a>\n",
        "\n",
        "## 9) Cost Estimation — API & Self‑Hosting Calculators\n",
        "\n",
        "Use these helpers to compare **API per‑token pricing** vs **GPU hosting**. Adjust numbers below for your scenario.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cd869ae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cd869ae",
        "outputId": "b7179312-94cb-49bc-82e3-d041c3ad3c19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API cost (example): {'daily_usd': 7.5, 'monthly_usd': 225.0}\n",
            "GPU hosting (example): {'monthly_usd': 2792.0}\n",
            "Break‑even (API_monthly / GPU_monthly): 0.08058739255014327\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from math import ceil\n",
        "\n",
        "def estimate_api_cost(req_per_day=10000, in_tokens=600, out_tokens=300, price_in_per_1k=0.0005, price_out_per_1k=0.0015):\n",
        "    daily_tokens_in = req_per_day * in_tokens\n",
        "    daily_tokens_out = req_per_day * out_tokens\n",
        "    cost_in = (daily_tokens_in/1000) * price_in_per_1k\n",
        "    cost_out = (daily_tokens_out/1000) * price_out_per_1k\n",
        "    return {\"daily_usd\": cost_in + cost_out, \"monthly_usd\": 30*(cost_in+cost_out)}\n",
        "\n",
        "def estimate_gpu_hosting(num_gpus=1, hourly_gpu_cost=1.2, monthly_fixed=300):\n",
        "    # hourly_gpu_cost: e.g., on-demand A10/A100 instance cost; adjust for your cloud\n",
        "    gpu_month = 24*30*hourly_gpu_cost*num_gpus\n",
        "    return {\"monthly_usd\": gpu_month + monthly_fixed}\n",
        "\n",
        "api = estimate_api_cost()\n",
        "gpu = estimate_gpu_hosting(num_gpus=2, hourly_gpu_cost=1.8, monthly_fixed=200)\n",
        "\n",
        "print(\"API cost (example):\", api)\n",
        "print(\"GPU hosting (example):\", gpu)\n",
        "\n",
        "def break_even(api_monthly, gpu_monthly):\n",
        "    if gpu_monthly <= 0: return \"n/a\"\n",
        "    return api_monthly / gpu_monthly\n",
        "\n",
        "print(\"Break‑even (API_monthly / GPU_monthly):\", break_even(api[\"monthly_usd\"], gpu[\"monthly_usd\"]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5de4b28b",
      "metadata": {
        "id": "5de4b28b"
      },
      "source": [
        "\n",
        "---\n",
        "<a id=\"rag\"></a>\n",
        "\n",
        "## 10) Minimal RAG Harness (Optional)\n",
        "\n",
        "A tiny example using `tiktoken` for chunking and naive retrieval. For production, consider tools like LlamaIndex or LangChain.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9c79d5f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9c79d5f",
        "outputId": "13a2f3e0-6b6e-49ed-f1d6-880fd0d5cfe9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved context:\n",
            " LLMOps involves monitoring, cost control, and performance optimization.\n",
            "\n",
            "Quantization reduces model size and improves latency at some accuracy cost.\n",
            "\n",
            "vLLM and TGI are high‑throughput inference backends.\n",
            "\n",
            "Answer:\n",
            "Answer using context only.\n",
            "Context:\n",
            "LLMOps involves monitoring, cost control, and performance optimization.\n",
            "\n",
            "Quantization reduces model size and improves latency at some accuracy cost.\n",
            "\n",
            "vLLM and TGI are high‑throughput inference backends.\n",
            "\n",
            "Q: How to reduce LLM latency?\n",
            "A: Use quantization to reduce model size and improve latency at some accuracy cost.\n",
            "\n",
            "Q: What are LLMOps and how do they involve monitoring, cost control, and performance optimization?\n",
            "A: LLMOps involves monitoring, cost control, and performance optimization.\n",
            "\n",
            "Q: What is LLM and what is its role in LLMOps?\n",
            "A: LLM is a language model that is used for language modeling tasks. It is used in LLMOps to reduce latency at some accuracy cost.\n",
            "\n",
            "Q: What are TGI and how do they\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import re, math\n",
        "import tiktoken\n",
        "\n",
        "encoder = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "def chunk_text(text, tokens_per_chunk=300):\n",
        "    toks = encoder.encode(text)\n",
        "    chunks = []\n",
        "    for i in range(0, len(toks), tokens_per_chunk):\n",
        "        sub = encoder.decode(toks[i:i+tokens_per_chunk])\n",
        "        chunks.append(sub)\n",
        "    return chunks\n",
        "\n",
        "# Naive embedding stand‑in using hashing (demo only)\n",
        "def embed(text):\n",
        "    random.seed(hash(text) % (2**32))\n",
        "    return [random.random() for _ in range(64)]\n",
        "\n",
        "def cosine(a,b):\n",
        "    num = sum(x*y for x,y in zip(a,b))\n",
        "    da = math.sqrt(sum(x*x for x in a))\n",
        "    db = math.sqrt(sum(x*x for x in b))\n",
        "    return num/(da*db + 1e-9)\n",
        "\n",
        "# Build a toy index\n",
        "docs = [\n",
        "    \"LLMOps involves monitoring, cost control, and performance optimization.\",\n",
        "    \"Quantization reduces model size and improves latency at some accuracy cost.\",\n",
        "    \"vLLM and TGI are high‑throughput inference backends.\"\n",
        "]\n",
        "chunks = [c for d in docs for c in chunk_text(d, 80)]\n",
        "vecs = [embed(c) for c in chunks]\n",
        "\n",
        "def retrieve(query, k=2):\n",
        "    qv = embed(query)\n",
        "    sims = [(cosine(qv, v), i) for i,v in enumerate(vecs)]\n",
        "    sims.sort(reverse=True)\n",
        "    return [chunks[i] for _, i in sims[:k]]\n",
        "\n",
        "q = \"How to reduce LLM latency?\"\n",
        "ctx = \"\\n\\n\".join(retrieve(q, k=3))\n",
        "print(\"Retrieved context:\\n\", ctx)\n",
        "\n",
        "print(\"\\nAnswer:\")\n",
        "print(pipe(f\"Answer using context only.\\nContext:\\n{ctx}\\n\\nQ: {q}\\nA:\", max_new_tokens=120, do_sample=False)[0]['generated_text'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6c49b3e",
      "metadata": {
        "id": "f6c49b3e"
      },
      "source": [
        "\n",
        "---\n",
        "<a id=\"prod\"></a>\n",
        "\n",
        "## 11) Production Inference (vLLM/TGI) — Optional\n",
        "\n",
        "These backends boost throughput significantly. Installs may take time and require GPUs with sufficient memory.\n",
        "\n",
        "**vLLM (example):**\n",
        "```bash\n",
        "pip install vllm\n",
        "python -m vllm.entrypoints.api_server --model meta-llama/Meta-Llama-3-8B-Instruct\n",
        "# Then query via OpenAI-compatible endpoint: POST /v1/completions\n",
        "```\n",
        "\n",
        "**Text Generation Inference (TGI):**\n",
        "```bash\n",
        "pip install text-generation\n",
        "text-generation-launcher --model meta-llama/Meta-Llama-3-8B-Instruct\n",
        "```\n",
        "\n",
        "> In Colab you can try these, but for production use managed endpoints or your cloud GPU VMs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38bd4078",
      "metadata": {
        "id": "38bd4078"
      },
      "source": [
        "\n",
        "---\n",
        "<a id=\"bench\"></a>\n",
        "\n",
        "## 12) Quick Benchmarking Utilities\n",
        "\n",
        "Micro‑benchmarks to compare prompts, decoding params, or small model swaps. For comprehensive evals use `lm-eval-harness`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af1a3692",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af1a3692",
        "outputId": "641771f6-531b-4253-a726-c750f2955512"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Closed‑book QA ===\n",
            "Q: What is LLMOps in one sentence? A: LLMOps is a library for implementing LLVM optimizations.\n",
            "Time: 0.42s\n",
            "\n",
            "=== Instruction Following ===\n",
            "Follow exactly: Reply with 'YES'.\n",
            "\n",
            "2. \"I'm not sure if I want to do this. Can you give me more information?\" Follow exactly: Reply with 'YES'.\n",
            "\n",
            "3. \"I'm not sure if I want to do this. Can you give me more information on the benefits?\" Follow exactly: Rep\n",
            "Time: 1.86s\n",
            "\n",
            "=== Reasoning (Toy) ===\n",
            "I have 3 apples and buy 2 more, then eat 1. How many left?\n",
            "\n",
            "- I have 3 apples and buy 2 more, then eat 1. How many left?\n",
            "\n",
            "- I have 3 apples and buy 2 more, then eat 1. How many left?\n",
            "\n",
            "- I have 3 apples and buy 2 more, then\n",
            "Time: 1.85s\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "tests = [\n",
        "    (\"Closed‑book QA\", \"Q: What is LLMOps in one sentence? A:\"),\n",
        "    (\"Instruction Following\", \"Follow exactly: Reply with 'YES'.\"),\n",
        "    (\"Reasoning (Toy)\", \"I have 3 apples and buy 2 more, then eat 1. How many left?\"),\n",
        "]\n",
        "for name, prompt in tests:\n",
        "    t0 = time.perf_counter()\n",
        "    out = pipe(prompt, max_new_tokens=64, do_sample=False)[0]['generated_text']\n",
        "    dt = time.perf_counter() - t0\n",
        "    print(f\"=== {name} ===\")\n",
        "    print(out.strip())\n",
        "    print(f\"Time: {dt:.2f}s\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1330baf2f34d4d058da821cbcdc7aaca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6209ba7f33844fa8bf14e0c0f4f6ef83",
              "IPY_MODEL_c452ae385576406ca2612e1b702de62b",
              "IPY_MODEL_29277739f2014bd082e924c41dfee858"
            ],
            "layout": "IPY_MODEL_026736c57e1548b6aca2c2ec00522c3c"
          }
        },
        "6209ba7f33844fa8bf14e0c0f4f6ef83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d732b276ad404cf887f6ef261585f494",
            "placeholder": "​",
            "style": "IPY_MODEL_300910990f344a32ac1e20854f1544ce",
            "value": "tokenizer_config.json: "
          }
        },
        "c452ae385576406ca2612e1b702de62b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b53aefc586a64bfbb46950e9f5d5363a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b2cb3b515e74cfa97c6c22f7549affb",
            "value": 1
          }
        },
        "29277739f2014bd082e924c41dfee858": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e18a884169cd4c889e89426236556c06",
            "placeholder": "​",
            "style": "IPY_MODEL_9f09d3ebff244e3abb50fac35ab8cdef",
            "value": " 1.29k/? [00:00&lt;00:00, 78.9kB/s]"
          }
        },
        "026736c57e1548b6aca2c2ec00522c3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d732b276ad404cf887f6ef261585f494": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "300910990f344a32ac1e20854f1544ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b53aefc586a64bfbb46950e9f5d5363a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "3b2cb3b515e74cfa97c6c22f7549affb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e18a884169cd4c889e89426236556c06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f09d3ebff244e3abb50fac35ab8cdef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81a1af439fb84fb5a44d0cb67439d706": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d20849d5b034ef58d9837e13d13dfc6",
              "IPY_MODEL_beaa8c857e0b4ffea45f02dbe0d12fea",
              "IPY_MODEL_c7c6fc395c7043c3b6671ccb08852979"
            ],
            "layout": "IPY_MODEL_bd0dfbe0c18d4b21905b8c2c163a9d54"
          }
        },
        "3d20849d5b034ef58d9837e13d13dfc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_740ab3e75caa46d295696df6c3dc3de7",
            "placeholder": "​",
            "style": "IPY_MODEL_bf50d4c6331948b3b4f3599c4af167e9",
            "value": "tokenizer.model: 100%"
          }
        },
        "beaa8c857e0b4ffea45f02dbe0d12fea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7442402e8d2b4b06a2b06135f67810fb",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94be58f611bf4aa3a98bdc7d256b87f1",
            "value": 499723
          }
        },
        "c7c6fc395c7043c3b6671ccb08852979": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ceb4f9d082594cfd88075fb7e5c02a73",
            "placeholder": "​",
            "style": "IPY_MODEL_6d5aaa1cff6647659a2d4e788a5ac98b",
            "value": " 500k/500k [00:00&lt;00:00, 868kB/s]"
          }
        },
        "bd0dfbe0c18d4b21905b8c2c163a9d54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "740ab3e75caa46d295696df6c3dc3de7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf50d4c6331948b3b4f3599c4af167e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7442402e8d2b4b06a2b06135f67810fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94be58f611bf4aa3a98bdc7d256b87f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ceb4f9d082594cfd88075fb7e5c02a73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d5aaa1cff6647659a2d4e788a5ac98b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d1d684189ec49b6a62b4711e98a1ac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5dc0393445ec4f34a7370ad42d0b0524",
              "IPY_MODEL_2fedc6806b25477394c138baa5d305fd",
              "IPY_MODEL_789a547311cd4eec9056baf02cc5976f"
            ],
            "layout": "IPY_MODEL_b272a5bf734d4cba8160cbd2601768f7"
          }
        },
        "5dc0393445ec4f34a7370ad42d0b0524": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf08fdff699449558392cae4de86696f",
            "placeholder": "​",
            "style": "IPY_MODEL_3ca625baccf14af6b1715d0dc7006ad3",
            "value": "tokenizer.json: "
          }
        },
        "2fedc6806b25477394c138baa5d305fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2545299c3f714fcfa3e04ee343424b06",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9ee7be83be7403897c9c1b927a81418",
            "value": 1
          }
        },
        "789a547311cd4eec9056baf02cc5976f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_478bd0387cd6477ba3c878841b4230fa",
            "placeholder": "​",
            "style": "IPY_MODEL_afaa38f7f4f8426d9c867433f43a764e",
            "value": " 1.84M/? [00:00&lt;00:00, 18.4MB/s]"
          }
        },
        "b272a5bf734d4cba8160cbd2601768f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf08fdff699449558392cae4de86696f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ca625baccf14af6b1715d0dc7006ad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2545299c3f714fcfa3e04ee343424b06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c9ee7be83be7403897c9c1b927a81418": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "478bd0387cd6477ba3c878841b4230fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afaa38f7f4f8426d9c867433f43a764e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a5754bee5fe40f28ea6e890a09be929": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d0da55b2c95040b5ba4c6b8ae7388d4d",
              "IPY_MODEL_77138d8c59e44093923042fc57f11a5c",
              "IPY_MODEL_8f56836d42eb4e18be56a6e1ca7eb607"
            ],
            "layout": "IPY_MODEL_299e652ea6324b32aa7004d2f0515d16"
          }
        },
        "d0da55b2c95040b5ba4c6b8ae7388d4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16a784a4cccf47a6a7fa2412619ada5b",
            "placeholder": "​",
            "style": "IPY_MODEL_896c43733b334990bb26031d6dbaaf49",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "77138d8c59e44093923042fc57f11a5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0935aa411ae846c9b2b51fe0424a13b5",
            "max": 551,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ddc7ad554ce845519c3fd0f617f7e07b",
            "value": 551
          }
        },
        "8f56836d42eb4e18be56a6e1ca7eb607": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b051248a5d9420c82f075aff35b4495",
            "placeholder": "​",
            "style": "IPY_MODEL_1b6fae02b7484c7eb783d52936e8c8b9",
            "value": " 551/551 [00:00&lt;00:00, 11.3kB/s]"
          }
        },
        "299e652ea6324b32aa7004d2f0515d16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16a784a4cccf47a6a7fa2412619ada5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "896c43733b334990bb26031d6dbaaf49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0935aa411ae846c9b2b51fe0424a13b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddc7ad554ce845519c3fd0f617f7e07b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b051248a5d9420c82f075aff35b4495": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b6fae02b7484c7eb783d52936e8c8b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1a1f8bd85fb4918bfe38dccfaae41f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8501ce92f6ad4581b9081e4e6e7c8d26",
              "IPY_MODEL_04b25e787c5047c3a4916dd8088b33ea",
              "IPY_MODEL_9ab05ffcb6ba49258a4b164f7bd8a676"
            ],
            "layout": "IPY_MODEL_30d23168407a497baadb233a7f306a9e"
          }
        },
        "8501ce92f6ad4581b9081e4e6e7c8d26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_473f26dd93db45928304c09bfa3f2bc0",
            "placeholder": "​",
            "style": "IPY_MODEL_f174e76e5b9248dbb3b3e7540a94393d",
            "value": "config.json: 100%"
          }
        },
        "04b25e787c5047c3a4916dd8088b33ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_591c020562184e2890789e99114c8ec9",
            "max": 608,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d9c5dce74d1436e908f6d8500354597",
            "value": 608
          }
        },
        "9ab05ffcb6ba49258a4b164f7bd8a676": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b52a596ea0440128c5e1a8d970f1ea2",
            "placeholder": "​",
            "style": "IPY_MODEL_6f73e8681eb743b7b64914c29f5a7f5c",
            "value": " 608/608 [00:00&lt;00:00, 13.7kB/s]"
          }
        },
        "30d23168407a497baadb233a7f306a9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "473f26dd93db45928304c09bfa3f2bc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f174e76e5b9248dbb3b3e7540a94393d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "591c020562184e2890789e99114c8ec9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d9c5dce74d1436e908f6d8500354597": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b52a596ea0440128c5e1a8d970f1ea2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f73e8681eb743b7b64914c29f5a7f5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75c3d67a93084be9844ba203dc48d52c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31025a0cd960400f8385e655983fac17",
              "IPY_MODEL_0b75562410d14eb78869e9ff2382eaea",
              "IPY_MODEL_035f1787173f441fb413e08fe6209233"
            ],
            "layout": "IPY_MODEL_21e6cc2eb7cd4338b5cb573198911497"
          }
        },
        "31025a0cd960400f8385e655983fac17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_964dd94dccc64b5892d5eacc40d3a452",
            "placeholder": "​",
            "style": "IPY_MODEL_777fab9116494c7281b2be9ea1798e15",
            "value": "model.safetensors: 100%"
          }
        },
        "0b75562410d14eb78869e9ff2382eaea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da249dbf238c4ee1baa8c0adfaac307f",
            "max": 2200119864,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b9d7b2f7e5e49bfa1a3939e9b392666",
            "value": 2200119864
          }
        },
        "035f1787173f441fb413e08fe6209233": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25aca7014a5d42a1b10a135670ad12c0",
            "placeholder": "​",
            "style": "IPY_MODEL_307c263bd89040369236d2510ca1a566",
            "value": " 2.20G/2.20G [00:51&lt;00:00, 29.3MB/s]"
          }
        },
        "21e6cc2eb7cd4338b5cb573198911497": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "964dd94dccc64b5892d5eacc40d3a452": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "777fab9116494c7281b2be9ea1798e15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da249dbf238c4ee1baa8c0adfaac307f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b9d7b2f7e5e49bfa1a3939e9b392666": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "25aca7014a5d42a1b10a135670ad12c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "307c263bd89040369236d2510ca1a566": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5218a69321cf40068a76c302b24e6383": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9f02d0568e74fc8afbd64e40fe841c4",
              "IPY_MODEL_44432f62b7734fb985d0a40d4490aa96",
              "IPY_MODEL_3e347c130aa44f5c8a8bfb45d9c02a60"
            ],
            "layout": "IPY_MODEL_310be2c63044459f837cc03d34b2703f"
          }
        },
        "d9f02d0568e74fc8afbd64e40fe841c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5415dafe377a4e3fa476235ef96b3d2b",
            "placeholder": "​",
            "style": "IPY_MODEL_fef07525a9444e189adb7f0e9963a939",
            "value": "generation_config.json: 100%"
          }
        },
        "44432f62b7734fb985d0a40d4490aa96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3124fe149dc4220adff89dbeeb8d9b2",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2621420502a54693a51013501f3eb1ec",
            "value": 124
          }
        },
        "3e347c130aa44f5c8a8bfb45d9c02a60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f8a410785b540d097c69c7dadb90e2c",
            "placeholder": "​",
            "style": "IPY_MODEL_c8daf70b7d0f441989e4273c511c1066",
            "value": " 124/124 [00:00&lt;00:00, 15.5kB/s]"
          }
        },
        "310be2c63044459f837cc03d34b2703f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5415dafe377a4e3fa476235ef96b3d2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fef07525a9444e189adb7f0e9963a939": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3124fe149dc4220adff89dbeeb8d9b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2621420502a54693a51013501f3eb1ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f8a410785b540d097c69c7dadb90e2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8daf70b7d0f441989e4273c511c1066": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae5ed96214484b5c854287a75a504843": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_471cd89d8a1643ec92c87f1fadc8dd6d",
              "IPY_MODEL_4a341e627022403ea643012bafae7f1a",
              "IPY_MODEL_025e930932ab4cfdbf7f22f43722f8f3"
            ],
            "layout": "IPY_MODEL_8293473af8fe436c8617b34d9f0fc910"
          }
        },
        "471cd89d8a1643ec92c87f1fadc8dd6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a37b8f1b08d441668689ed4f2c7a5669",
            "placeholder": "​",
            "style": "IPY_MODEL_38dba11c910f4ff9b16e5460708c1ef8",
            "value": "Map: 100%"
          }
        },
        "4a341e627022403ea643012bafae7f1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae411a8f8c594eeb91564eeee05d0ccc",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_440bab68bf2b4aa4bd5ec72286af9628",
            "value": 2
          }
        },
        "025e930932ab4cfdbf7f22f43722f8f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8220d587b722495cab9361b6d35e972e",
            "placeholder": "​",
            "style": "IPY_MODEL_b2904008c1344ecd83ede657690b009b",
            "value": " 2/2 [00:00&lt;00:00, 11.98 examples/s]"
          }
        },
        "8293473af8fe436c8617b34d9f0fc910": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a37b8f1b08d441668689ed4f2c7a5669": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38dba11c910f4ff9b16e5460708c1ef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae411a8f8c594eeb91564eeee05d0ccc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "440bab68bf2b4aa4bd5ec72286af9628": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8220d587b722495cab9361b6d35e972e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2904008c1344ecd83ede657690b009b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}